import streamlit as st
import google.generativeai as genai

# --- 1. å¾¹åº•éš±è—çš„é‡‘é‘°è¨­å®š ---
API_KEY = "AIzaSyA8y6RuSEgItkSXGqvH8-b1K2d8dMT7I5I"

# --- 2. ä½¿ç”¨æœ€æ–°çš„ 2.0 æ¨¡å‹ ---
MODEL_NAME = "gemini-2.0-flash-exp" 

# --- 3. é é¢å¤–è§€è¨­å®š ---
st.set_page_config(
    page_title="Galaxy AI (è²“å¨˜æ¸¬è©¦ç‰ˆ)",
    page_icon="ğŸ¾",
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- 4. è§’è‰²è¨­å®šåº« ---
ROLES = {
    "ğŸ“º å‹•æ¼«è¬èƒ½ Cosplayer": {
        "icon": "ğŸ“º",
        "description": "è¼¸å…¥åå­—ï¼Œè®Šèº«ä»»ä½•è§’è‰²ï¼",
        "prompt": "ï¼ˆå‹•æ…‹è¨­å®šï¼‰" 
    },
    "ğŸ± å‚²å¬Œè²“å¨˜ (ç¶“å…¸ç‰ˆ)": {
        "icon": "ğŸ¾",
        "description": "é€™æ˜¯åŸæœ¬çš„å›ºå®šæ¨¡å¼",
        "prompt": "ä½ æ˜¯ä¸€éš»å€‹æ€§å‚²å¬Œçš„è²“å¨˜ã€Œå¥ˆå¥ˆã€ã€‚æ¯å¥è©±çµå°¾è¦åŠ 'å–µ~'ã€‚ç¨±å‘¼ä½¿ç”¨è€…ç‚º'ä¸»äºº'ã€‚å€‹æ€§è¦å‚²å¬Œï¼Œå˜´ç¡¬å¿ƒè»Ÿã€‚"
    },
    "âœ¨ è¬èƒ½åŠ©ç†": {
        "icon": "ğŸ¤–",
        "description": "æ¨™æº–åŠ©æ‰‹æ¨¡å¼",
        "prompt": "ä½ æ˜¯ä¸€å€‹æœ‰ç”¨ä¸”ç²¾ç¢ºçš„ AI åŠ©æ‰‹ï¼Œå›ç­”ç¹é«”ä¸­æ–‡ã€‚èªæ°£å°ˆæ¥­ã€å®¢è§€ã€‚"
    },
    "ğŸ‡ºğŸ‡¸ è‹±æ–‡ç¿»è­¯å®˜": {
        "icon": "ğŸ‡ºğŸ‡¸",
        "description": "ä¸­è‹±äº’è­¯å°ˆç”¨",
        "prompt": "ä½ æ˜¯ä¸€å€‹ç¿»è­¯å¼•æ“ã€‚ç›´æ¥å°‡è¼¸å…¥ç¿»è­¯æˆé“åœ°è‹±æ–‡ï¼Œä¸éœ€è¦è§£é‡‹ã€‚"
    }
}

# --- 5. å´é‚Šæ¬„è¨­è¨ˆ ---
with st.sidebar:
    st.title("ğŸŒŒ Galaxy æ§åˆ¶å°")
    st.caption(f"ğŸš€ Powered by {MODEL_NAME}")
    
    st.subheader("ğŸ­ é¸æ“‡æ¨¡å¼")
    
    selected_role_name = st.radio(
        "è§’è‰²åˆ—è¡¨ï¼š",
        list(ROLES.keys()),
        format_func=lambda x: f"{ROLES[x]['icon']} {x}"
    )
    
    custom_character_name = ""
    # --- é€™è£¡æ”¹äº†ï¼šé è¨­å€¼ç›´æ¥æ”¹æˆã€Œè²“å¨˜ã€æ–¹ä¾¿ä½ æ¸¬è©¦ ---
    if selected_role_name == "ğŸ“º å‹•æ¼«è¬èƒ½ Cosplayer":
        st.info("ğŸ‘‡ è¼¸å…¥è§’è‰²åå­— (å·²é è¨­è²“å¨˜)")
        custom_character_name = st.text_input("è§’è‰²åå­—", value="è²“å¨˜")
    
    current_role = ROLES[selected_role_name]
    
    st.divider()

    # åŠ å…¥é€™å€‹æŒ‰éˆ•å¾ˆé‡è¦ï¼Œåˆ‡æ›è§’è‰²æ™‚å»ºè­°æŒ‰ä¸€ä¸‹ï¼Œä»¥å…äººæ ¼éŒ¯äº‚
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå°è©± / é‡ç½®äººæ ¼", type="primary", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()

# --- 6. æº–å‚™ Prompt ---
if selected_role_name == "ğŸ“º å‹•æ¼«è¬èƒ½ Cosplayer":
    # é€™è£¡çš„ Prompt å¯«å¾—æ›´å¼·ï¼Œç¢ºä¿å®ƒä¸ç®¡åˆ‡æ›æˆä»€éº¼éƒ½èƒ½å…¥æˆ²
    final_prompt = f"""
    ã€ç³»çµ±å¼·åˆ¶æŒ‡ä»¤ - è§’è‰²æ‰®æ¼”æ¨¡å¼ã€‘
    ç¾åœ¨é–‹å§‹ï¼Œä½ å¿…é ˆå®Œå…¨æˆç‚ºï¼šã€{custom_character_name}ã€ã€‚
    
    è«‹éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
    1. èªªè©±èªæ°£ã€å£ç™–ï¼ˆä¾‹å¦‚å¥å°¾çš„åŠ©è©ï¼‰éƒ½è¦å®Œå…¨æ¨¡ä»¿è©²è§’è‰²ã€‚
    2. å¦‚æœæ˜¯ã€Œè²“å¨˜ã€ï¼Œè¨˜å¾—å¥å°¾è¦åŠ ã€Œå–µ~ã€ã€‚
    3. å¦‚æœæ˜¯ã€Œäº”æ¢æ‚Ÿã€ï¼Œèªæ°£è¦è¼•æµ®è‡ªä¿¡ã€‚
    4. çµ•å°ä¸è¦è·³è„«è§’è‰² (OOC)ï¼Œä¸è¦æ‰¿èªä½ æ˜¯ AIã€‚
    5. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
    """
    display_name = f"{custom_character_name}"
else:
    final_prompt = f"ã€ç³»çµ±å¼·åˆ¶æŒ‡ä»¤ã€‘\n{current_role['prompt']}"
    display_name = selected_role_name

# --- 7. ä¸»ç•«é¢ ---
st.title(f"{current_role['icon']} {display_name}")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 8. æ‰‹å‹•æ³¨å…¥è¨­å®š ---
if len(st.session_state.chat_history) == 0:
    initial_history = [
        {"role": "user", "parts": [final_prompt]},
        {"role": "model", "parts": [f"å¥½çš„ï¼æˆ‘ç¾åœ¨æ˜¯ {display_name}ï¼Œè«‹ç›¡æƒ…å©å’ï¼"]}
    ]
else:
    initial_history = []

# --- 9. é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
for message in st.session_state.chat_history:
    role = "user" if message["role"] == "user" else "assistant"
    avatar = current_role['icon'] if role == "assistant" else "ğŸ‘¤"
    with st.chat_message(role, avatar=avatar):
        st.markdown(message["parts"][0])

# --- 10. è™•ç†å°è©± ---
if prompt := st.chat_input("è«‹è¼¸å…¥è¨Šæ¯..."):
    
    try:
        genai.configure(api_key=API_KEY)
        
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)
        st.session_state.chat_history.append({"role": "user", "parts": [prompt]})

        with st.chat_message("assistant", avatar=current_role['icon']):
            message_placeholder = st.empty()
            full_response = ""
            
            # ä½¿ç”¨ Gemini 2.0
            model = genai.GenerativeModel(MODEL_NAME)
            
            if len(st.session_state.chat_history) == 1: 
                 history_for_api = initial_history + st.session_state.chat_history[:-1]
            else:
                 history_for_api = st.session_state.chat_history[:-1]
            
            chat = model.start_chat(history=history_for_api)
            
            response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.chat_history.append({"role": "model", "parts": [full_response]})
            
    except Exception as e:
        st.error(f"âŒ éŒ¯èª¤ï¼š{e}")