import streamlit as st
import google.generativeai as genai
import time

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Gemini å…è²» AI åŠ©æ‰‹",
    page_icon="âœ¨",
    layout="centered"
)

st.title("âœ¨ Gemini å…è²»ç„¡é™èŠ")
st.caption("ğŸš€ ä½¿ç”¨ Google Gemini Pro æ¨¡å‹ (Free Tier)")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    # é€™è£¡è®“ä½¿ç”¨è€…è¼¸å…¥ Google çš„ Key
    google_api_key = st.text_input("Google API Key", type="password", help="AIzaSyDhcyR0K1FsSABRQUxglo1U-J_gFiU376U")
    st.markdown("[å–å¾—å…è²» Key](https://aistudio.google.com/app/apikey)")
    
    st.divider()
    
    # æ¸…é™¤è¨˜æ†¶æŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", type="primary"):
        st.session_state.chat_history = []
        st.rerun()

# --- 3. åˆå§‹åŒ–è¨˜æ†¶ ---
# Gemini çš„è¨˜æ†¶æ ¼å¼è·Ÿ OpenAI ä¸å¤ªä¸€æ¨£ï¼Œæˆ‘å€‘é€™è£¡ç”¨ Google å®˜æ–¹æ¨è–¦çš„æ–¹å¼ç®¡ç†
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 4. é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
# éæ­·æ­·å²ç´€éŒ„ä¸¦ç•«åœ¨è¢å¹•ä¸Š
for message in st.session_state.chat_history:
    # Google çš„è§’è‰²åç¨±æ˜¯ 'user' å’Œ 'model'ï¼Œæˆ‘å€‘è½‰æ›ä¸€ä¸‹é¡¯ç¤ºåç¨±
    role = "user" if message["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message["parts"][0])

# --- 5. è™•ç†å°è©± ---
if prompt := st.chat_input("è¼¸å…¥ä½ æƒ³å•çš„äº‹..."):
    
    # æª¢æŸ¥ Key
    if not google_api_key:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ Google API Key å–”ï¼")
        st.stop()
    
    # è¨­å®š Google API
    try:
        genai.configure(api_key=google_api_key)
    except Exception as e:
        st.error(f"API Key è¨­å®šå¤±æ•—: {e}")
        st.stop()

    # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # åŠ å…¥æ­·å²ç´€éŒ„ (æš«å­˜é¡¯ç¤ºç”¨)
    st.session_state.chat_history.append({"role": "user", "parts": [prompt]})

    # å‘¼å« Gemini å¤§è…¦
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # åˆå§‹åŒ–æ¨¡å‹ (gemini-1.5-flash æ˜¯ç›®å‰æœ€å¿«ä¸”å…è²»é¡åº¦é«˜çš„æ¨¡å‹)
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # å»ºç«‹èŠå¤©ç‰©ä»¶ (å¸¶å…¥éå»çš„æ­·å²ç´€éŒ„)
            chat = model.start_chat(history=st.session_state.chat_history[:-1]) # å‚³å…¥é™¤äº†æœ€æ–°é€™å¥ä»¥å¤–çš„æ­·å²
            
            # ç™¼é€è¨Šæ¯ä¸¦å–å¾—ä¸²æµå›æ‡‰
            response = chat.send_message(prompt, stream=True)
            
            # é¡¯ç¤ºæ‰“å­—æ©Ÿæ•ˆæœ
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # å°‡ AI çš„å›æ‡‰åŠ å…¥è¨˜æ†¶
            st.session_state.chat_history.append({"role": "model", "parts": [full_response]})
            
        except Exception as e:
            st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            # é€™è£¡å¸¸è¦‹çš„éŒ¯èª¤å¯èƒ½æ˜¯ Free Tier çš„é€Ÿç‡é™åˆ¶ (Rate Limit)
            # å¦‚æœèŠå¤ªå¿«ï¼ŒGoogle æœƒæš«æ™‚æ“‹ä¸€ä¸‹ï¼Œç¨ç­‰å¹¾ç§’å°±å¥½